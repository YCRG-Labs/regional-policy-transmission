{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np \n",
    "import datetime \n",
    "import glob\n",
    "from fredapi import Fred\n",
    "fred = Fred(api_key='')\n",
    "base_url = 'https://api.stlouisfed.org/fred/'\n",
    "\n",
    "state_abbreviations = [\n",
    "'AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA',\n",
    "    'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD',\n",
    "    'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ',\n",
    "    'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC',\n",
    "    'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY'\n",
    "]\n",
    "regions = {\n",
    "    \"Northeast\": [\"ME\", \"NH\", \"VT\", \"MA\", \"RI\", \"CT\", \"NY\", \"NJ\", \"PA\"],\n",
    "    \"Midwest\": [\"OH\", \"MI\", \"IN\", \"IL\", \"WI\", \"MN\", \"IA\", \"MO\", \"ND\", \"SD\", \"NE\", \"KS\"],\n",
    "    \"South\": [\"DE\", \"MD\", \"VA\", \"WV\", \"NC\", \"SC\", \"GA\", \"FL\", \"KY\", \"TN\", \"MS\", \"AL\", \"OK\", \"TX\", \"AR\", \"LA\"],\n",
    "    \"West\": [\"ID\", \"MT\", \"WY\", \"NV\", \"UT\", \"CO\", \"AZ\", \"NM\", \"AK\", \"WA\", \"OR\", \"CA\", \"HI\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in state_abbreviations:\n",
    "    series_id = f'EMPLOY{state}'  \n",
    "    try:\n",
    "        # fetch jobs\n",
    "        data = fred.get_series(series_id, observation_start='1990-01-01', observation_end='2023-12-31')\n",
    "        df = pd.DataFrame({f'{state}_employment': data})\n",
    "        df.index.name = \"Date\"\n",
    "\n",
    "        # save csv\n",
    "        df.to_csv(f'{state}_employmentdata.csv')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve data for {state}: {e}\")\n",
    "        \n",
    "\n",
    "\n",
    "# EMPLOY IS QUARTERLY, NOT SEASONALLY ADJUSTED, THIS IS AN AVERAGE\n",
    "#counted by persons (unit)\n",
    "#(state_employmentdata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c15160",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24342ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m series_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mUR\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseries_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1990-01-01\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservation_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2023-12-31\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_unemploymentdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data})\n\u001b[1;32m     12\u001b[0m     df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fredapi/fred.py:161\u001b[0m, in \u001b[0;36mFred.get_series\u001b[0;34m(self, series_id, observation_start, observation_end, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(val)\n\u001b[0;32m--> 161\u001b[0m     data[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/fredapi/fred.py:95\u001b[0m, in \u001b[0;36mFred._parse\u001b[0;34m(self, date_str, format)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_parse\u001b[39m(\u001b[38;5;28mself\u001b[39m, date_str, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    helper function for parsing FRED date string into datetime\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(rv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto_pydatetime\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     97\u001b[0m         rv \u001b[38;5;241m=\u001b[39m rv\u001b[38;5;241m.\u001b[39mto_pydatetime()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:1106\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mbool_):\n\u001b[1;32m   1108\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(result)  \u001b[38;5;66;03m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    438\u001b[0m     arg,\n\u001b[1;32m    439\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m )\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:484\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_string_array(result):\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Index(result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:566\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    563\u001b[0m         data \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39m_dtype_obj)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex must be specified when data is not list-like\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/construction.py:577\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    573\u001b[0m     data \u001b[38;5;241m=\u001b[39m construct_1d_arraylike_from_scalar(data, \u001b[38;5;28mlen\u001b[39m(index), dtype)\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m--> 577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mABCExtensionArray\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;66;03m# it is already ensured above this is not a NumpyExtensionArray\u001b[39;00m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;66;03m# Until GH#49309 is fixed this check needs to come before the\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;66;03m#  ExtensionDtype check\u001b[39;00m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/generic.py:44\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[0;34m(cls, inst)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/dtypes/generic.py:38\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._check\u001b[0;34m(inst)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check\u001b[39m(inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_typ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m comp\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for state in state_abbreviations: \n",
    "\n",
    "    series_id = f\"{state}UR\"  \n",
    "    try:\n",
    "        data = fred.get_series(\n",
    "            series_id,\n",
    "            observation_start=\"1990-01-01\",\n",
    "            observation_end=\"2023-12-31\"\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame({f\"{state}_unemploymentdata\": data})\n",
    "        df.index.name = \"Date\"\n",
    "\n",
    "        #reindex to quartely\n",
    "        quarterly_dates = pd.date_range(start=\"1990-01-01\", end=\"2023-10-01\", freq='QS')  # quarter start\n",
    "        df = df.reindex(quarterly_dates)\n",
    "\n",
    "        #mi check\n",
    "        df[f\"{state}_unemploymentdata\"] = df[f\"{state}_unemploymentdata\"].interpolate(method='linear')\n",
    "\n",
    "        #tail\n",
    "        tail_values = df.tail(3)[f\"{state}_unemploymentdata\"]\n",
    "        avg_value = round(tail_values.mean())\n",
    "        df.iloc[-3:, 0] = avg_value\n",
    "\n",
    "        df.index.name = \"Date\"\n",
    "        df.to_csv(f\"{state}_unemploymentdata.csv\")\n",
    "         \n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve data for {state}: {e}\")\n",
    "#unemployment rate by state\n",
    "#Percent, Seasonally Adjusted,  Monthly\n",
    "#(state_unemploymentdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c92230af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in state_abbreviations:\n",
    "    series_id = f'{state}PHCI'\n",
    "    try:\n",
    "        data = fred.get_series(\n",
    "            series_id,\n",
    "            observation_start=\"1990-01-01\",\n",
    "            observation_end=\"2023-12-31\"\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame({f\"{state}_coaindex\": data})\n",
    "        df.index.name = \"Date\"\n",
    "\n",
    "        #reindex to quartely\n",
    "        quarterly_dates = pd.date_range(start=\"1990-01-01\", end=\"2023-10-01\", freq='QS')  # quarter start\n",
    "        df = df.reindex(quarterly_dates)\n",
    "\n",
    "        #mi check\n",
    "        df[f\"{state}_coaindex\"] = df[f\"{state}_coaindex\"].interpolate(method='linear')\n",
    "\n",
    "        #tail\n",
    "        tail_values = df.tail(3)[f\"{state}_coaindex\"]\n",
    "        avg_value = round(tail_values.mean())\n",
    "        df.iloc[-3:, 0] = avg_value\n",
    "\n",
    "        df.index.name = \"Date\"\n",
    "        df.to_csv(f\"{state}_coaindex.csv\")\n",
    "         \n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve data for {state}: {e}\")\n",
    "\n",
    "#THIS IS Monthly, Seasonally Adjusted, Coincident Economic Activity Index for STATES INDEX\n",
    "# add Industrial production by region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Industrial production by region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e220a6",
   "metadata": {},
   "source": [
    "Prices and Wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18020681",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_series = [\n",
    "    \"CUURA101SA0\",\n",
    "    \"CUURA422SA0\",\n",
    "    \"CUURA423SA0\",\n",
    "    \"CUURA103SA0\",\n",
    "    \"CUURA207SA0\",\n",
    "    \"CUURA320SA0\",\n",
    "    \"CUURA316SA0\",\n",
    "    \"CUURA102SA0\",\n",
    "    \"CUURA318SA0\",\n",
    "    \"CUURA319SA0\",\n",
    "    \"CUURA208SA0\"\n",
    "]\n",
    "\n",
    "for series in cpi_series:\n",
    "    try: \n",
    "        data = fred.get_series(\n",
    "            series,    \n",
    "            observation_start='1990-01-01', \n",
    "            observation_end='2023-12-31'\n",
    "        )\n",
    "        regional_cpi[series] = data\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve data for {state}: {e}\")\n",
    "# monthly, not seasonally adjusted\n",
    "#  Regional CPIs (available metropolitan areas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849cf122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_series_ids = {\n",
    "    'AL': 'ALWTOT', 'AK': 'AKWTOT', 'AZ': 'AZWTOT', 'AR': 'ARWTOT', 'CA': 'CAWTOT',\n",
    "    'CO': 'COWTOT', 'CT': 'CTWTOT', 'DE': 'DEWTOT', 'FL': 'FLWTOT', 'GA': 'GAWTOT',\n",
    "    'HI': 'HIWTOT', 'ID': 'IDWTOT', 'IL': 'ILWTOT', 'IN': 'INWTOT', 'IA': 'IAWTOT',\n",
    "    'KS': 'KSWTOT', 'KY': 'KYWTOT', 'LA': 'LAWTOT', 'ME': 'MEWTOT', 'MD': 'MDWTOT',\n",
    "    'MA': 'MAWTOT', 'MI': 'MIWTOT', 'MN': 'MNWTOT', 'MS': 'MSWTOT', 'MO': 'MOWTOT',\n",
    "    'MT': 'MTWTOT', 'NE': 'NEWTOT', 'NV': 'NVWTOT', 'NH': 'NHWTOT', 'NJ': 'NJWTOT',\n",
    "    'NM': 'NMWTOT', 'NY': 'NYWTOT', 'NC': 'NCWTOT', 'ND': 'NDWTOT', 'OH': 'OHWTOT',\n",
    "    'OK': 'OKWTOT', 'OR': 'ORWTOT', 'PA': 'PAWTOT', 'RI': 'RIWTOT', 'SC': 'SCWTOT',\n",
    "    'SD': 'SDWTOT', 'TN': 'TNWTOT', 'TX': 'TXWTOT', 'UT': 'UTWTOT', 'VT': 'VTWTOT',\n",
    "    'VA': 'VAWTOT', 'WA': 'WAWTOT', 'WV': 'WVWTOT', 'WI': 'WIWTOT', 'WY': 'WYWTOT'\n",
    "}\n",
    "for state in state_abbreviations:\n",
    "    series_id = state_series_ids.get(state)\n",
    "    try:\n",
    "        data = fred.get_series(series_id, observation_start='1990-01-01', observation_end='2023-12-31')\n",
    "        df = pd.DataFrame({f'{state}_wagevalue': data})\n",
    "        df.index.name = \"Date\"\n",
    "        df.to_csv(f'{state}_wagegrowthdata.csv')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve data for {state}: {e}\")\n",
    "\n",
    "for state in state_abbreviations:\n",
    "    series_id = f\"{state}NA\"  \n",
    "    try:\n",
    "        data = fred.get_series(\n",
    "            series_id,\n",
    "            observation_start=\"1990-01-01\",\n",
    "            observation_end=\"2023-12-31\"\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame({f\"{state}_workingpeople\": data})\n",
    "        df.index.name = \"Date\"\n",
    "\n",
    "        #reindex to quartely\n",
    "        quarterly_dates = pd.date_range(start=\"1990-01-01\", end=\"2023-10-01\", freq='QS')  # quarter start\n",
    "        df = df.reindex(quarterly_dates)\n",
    "\n",
    "        #mi check\n",
    "        df[f\"{state}_workingpeople\"] = df[f\"{state}_workingpeople\"].interpolate(method='linear')\n",
    "\n",
    "        #tail\n",
    "        tail_values = df.tail(3)[f\"{state}_workingpeople\"]\n",
    "        avg_value = round(tail_values.mean())\n",
    "        df.iloc[-3:, 0] = avg_value\n",
    "\n",
    "        df.index.name = \"Date\"\n",
    "        df.to_csv(f\"{state}_workingpeople.csv\")\n",
    "         \n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve data for {state}: {e}\")\n",
    "#i had to do this because no average could be found so i had to do it myself, multiplied by 1000 due to factor in both TWOT and NA datasets as that\n",
    "for state in state_abbreviations:\n",
    "    try:\n",
    "        #load csv\n",
    "        wage_df = pd.read_csv(f\"{state}_wagegrowthdata.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "        work_df = pd.read_csv(f\"{state}_workingpeople.csv\", parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "        \n",
    "        #dates\n",
    "        common_index = wage_df.index.intersection(work_df.index)\n",
    "        wage_df = wage_df.loc[common_index]\n",
    "        work_df = work_df.loc[common_index]\n",
    "        \n",
    "        #avoid zero\n",
    "        work_df = work_df.replace(0, np.nan)\n",
    "        \n",
    "        #wage per person\n",
    "        ratio_df = pd.DataFrame({f\"{state}_ratio\": wage_df.iloc[:, 0] / work_df.iloc[:, 0]})\n",
    "        \n",
    "        #missing values\n",
    "        ratio_df[f\"{state}_ratio\"] = ratio_df[f\"{state}_ratio\"].interpolate(method='linear')\n",
    "        \n",
    "        #quarter-quarter-percent change\n",
    "        growth_df = ratio_df.pct_change() * 100  # convert fraction to percent\n",
    "        growth_df.rename(columns={f\"{state}_ratio\": f\"{state}_growth\"}, inplace=True)\n",
    "        \n",
    "        #save csv\n",
    "        growth_df.to_csv(f\"{state}_growth.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {state}: {e}\")\n",
    "\n",
    "#state_growth.csv\n",
    "#Date, WY_growth\n",
    "#seasonally adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hpi\n",
    "housing_price_indices  = {}\n",
    "for state in state_abbreviations:\n",
    "    series_id = f'{state}STHPI'\n",
    "    try:\n",
    "        # j*bs\n",
    "        data = fred.get_series(series_id, observation_start='1990-01-01', observation_end='2023-12-31')\n",
    "        df = pd.DataFrame({f'{state}_hpi': data})\n",
    "        df.index.name = \"Date\"\n",
    "\n",
    "        df.to_csv(f'{state}_hpi.csv')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve data for {state}: {e}\")\n",
    "# Quarterly, Not Seasonally Adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda58420",
   "metadata": {},
   "source": [
    "Financial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cdc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'regional_lending.csv'\n"
     ]
    }
   ],
   "source": [
    "#regional banking, MUST AGGREGRATE DIFFERENTLY!!!\n",
    "series_id = 'DRTSCILM'\n",
    "data = fred.get_series(series_id, observation_start='1990-01-01', observation_end='2023-12-31')\n",
    "df = pd.DataFrame({'regional_lending': data})\n",
    "df.index.name = 'Date'\n",
    "df.to_csv('regional_lending.csv')\n",
    "#unseasoned data\n",
    "print(\"Data saved to 'regional_lending.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1bf114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proxy for mortgage \n",
    "files = glob.glob('*_coaindex.csv')\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, parse_dates=['Date'], index_col='Date')\n",
    "    \n",
    "    mortgage_proxy = df.iloc[:, 0].pct_change() * 100\n",
    "    \n",
    "    df_proxy = pd.DataFrame({'mortgage_proxy_qoq': mortgage_proxy}, index=df.index)\n",
    "    \n",
    "    state = file.split('_')[0]  \n",
    "    new_filename = f'{state}_proxymortgageapplications.csv'\n",
    "    df_proxy.to_csv(new_filename)\n",
    "    \n",
    "    print(f\"Saved mortgage proxy for {state} as {new_filename}\")\n",
    "\n",
    "print(\"All state mortgage proxies saved successfully.\")\n",
    "\n",
    "#yeah i had to proxy because the other state level report was hundreds of dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42557bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#small businesses â€¢ Small business lending conditions https://fred.stlouisfed.org/series/SUBLPDCISSOTHNQ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
